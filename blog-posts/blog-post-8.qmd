---
title: Generalized Additive Models (GAMs) for Meta-Regression using `brms`

author: "Matthew B. Jané"
image: "blog-image.png"
image-height: "5%"
toc: true
code-fold: false
date: 2024-09-24
description: A GAM is a linear or generalized linear model that allows you to model non-linear relationships using splines, smooth functions that allows to model the "wiggiliness" in the data. To my knowledge there is little/nothing out there regarding the use of GAMs in a meta-analysis context.

categories:
  - Generalized Additive Models
  - Meta-regression

title-meta: Generalized Additive Models for Meta-Regression using `brms`
author-meta: "Matthew B. Jané"
date-meta: 2024-02-02
image-meta: "blog-image.png"
bibliography: references.bib
---

```{=html}
<a href="https://www.buymeacoffee.com/matthewbjane"><img src="https://img.buymeacoffee.com/button-api/?text=Support my work&emoji=☕&slug=matthewbjane&button_colour=ed5c9b&font_colour=ffffff&font_family=Arial&outline_colour=ffffff&coffee_colour=ffffff" /></a>
```
<br>

## What would a meta-analytic GAM look like?

**This brief intro section is a sort of a meta-analytic adaptation of a [section](https://m-clark.github.io/generalized-additive-models/building_gam.html#what-is-a-gam) of Michael Clark's online text "Generalized Additive Models".**


Let's first consider a simple linear meta-regression model where an observed effect size $d_i$ from study $i$ is expressed as,

$$
d_i = \underset{_\textrm{intercept}}{b_0} + \overset{^\textrm{moderator effect}}{b_1M_i} + \underset{_\textrm{true effect variability}}{u_i} + \overset{^\textrm{sampling error}}{\varepsilon_i}.
$$
The first three terms in the equation is what defines the true effect size $\delta_i$ for study $i$ and the last term denotes sampling error which is what distinguishes the observed effect size $d_i$ from the true effect size $\delta_i$. The true effect size is conditionally distributed as,

$$
\delta_i | M \sim \mathcal{N}\left(b_0 + b_1M_i\, ,\, \tau^2\right)
$$
Where $\tau^2$ is the variance in true effects (i.e., $\tau^2 = \mathrm{var}(u_i)$). We can see that the conditional expectation of true effects is a linear function of the moderator variable $\mathbb{E}[\delta_i \mid M] = b_0 + b_1M_i$. But we don't have to model the conditional mean as linear. We can model it as any arbitrary function $f$ such that the conditional mean has any functional form,


$$
\delta_i | M \sim \mathcal{N}\left(f(M),\, \tau^2\right).
$$

For GAMs we elect to choose a space of functions (e.g., cubic splines) called a **basis**. A function within the function space can be expressed as a linear combination of basis functions. For our case, the function $f(M)$ can be expressed as, $f(M) = \sum^m_{q=1} \xi_q(M)$, where $\xi_q$ are basis functions. Therefore the conditional distribution of true effects is now given by,

$$
\delta_i | M \sim \mathcal{N}\left(\sum^m_{q=1} b_q\xi_q(M),\, \tau^2\right).
$$

The conditional expectation of true effects now can have maximum flexibility. To estimate the conditional expectation, GAMs utilize **penalized splines** which penalizes the function for being too "wiggly" so as to maintain a parsimonious model. The number of knots also does not have to be set manually like they do in other spline models.


## Loading in packages

We will need the following packages before we begin.

```{r,message=FALSE,warning=FALSE}
library(tidyverse)
library(brms)
library(mgcv)
library(tidybayes)
library(modelr)
library(ggdist)
```


## Non-linear Data

We can use some made up non-linear data created by Wolfgang Viechtbauer in his [tutorial](https://www.metafor-project.org/doku.php/tips:non_linear_meta_regression) on spling meta-regression.

```{r}
dat <- structure(list(
  # effect size data
  yi = c(0.99, 0.54, -0.01, 1.29, 0.66, -0.12, 1.18,-0.23, 0.03, 0.73, 1.27, 0.38, -0.19, 0.01, 0.31, 1.41, 1.32, 1.22, 1.24,-0.05, 1.17, -0.17, 1.29, -0.07, 0.04, 1.03, -0.16, 1.25, 0.27, 0.27, 0.07,0.02, 0.7, 1.64, 1.66, 1.4, 0.76, 0.8, 1.91, 1.27, 0.62, -0.29, 0.17, 1.05,-0.34, -0.21, 1.24, 0.2, 0.07, 0.21, 0.95, 1.71, -0.11, 0.17, 0.24, 0.78,1.04, 0.2, 0.93, 1, 0.77, 0.47, 1.04, 0.22, 1.42, 1.24, 0.15, -0.53, 0.73,0.98, 1.43, 0.35, 0.64, -0.09, 1.06, 0.36, 0.65, 1.05, 0.97, 1.28), 
  # standard error
  sei = sqrt(c(0.018, 0.042, 0.031, 0.022, 0.016, 0.013, 0.066, 0.043, 0.092, 0.009,0.018, 0.034, 0.005, 0.005, 0.015, 0.155, 0.004, 0.124, 0.048, 0.006, 0.134,0.022, 0.004, 0.043, 0.071, 0.01, 0.006, 0.128, 0.1, 0.156, 0.058, 0.044,0.098, 0.154, 0.117, 0.013, 0.055, 0.034, 0.152, 0.022, 0.134, 0.038, 0.119,0.145, 0.037, 0.123, 0.124, 0.081, 0.005, 0.026, 0.018, 0.039, 0.062, 0.012,0.132, 0.02, 0.138, 0.065, 0.005, 0.013, 0.101, 0.051, 0.011, 0.018, 0.012,0.059, 0.111, 0.073, 0.047, 0.01, 0.007, 0.055, 0.019, 0.104, 0.056, 0.006,0.094, 0.009, 0.008, 0.02 )), 
  # moderator values
  xi = c(9.4, 6.3, 1.9, 14.5, 8.4, 1.8, 11.3,4.8, 0.7, 8.5, 15, 11.5, 4.5, 4.3, 4.3, 14.7, 11.4, 13.4, 11.5, 0.1, 12.3,1.6, 14.6, 5.4, 2.8, 8.5, 2.9, 10.1, 0.2, 6.1, 4, 5.1, 12.4, 10.1, 13.3,12.4, 7.6, 12.6, 12, 15.5, 4.9, 0.2, 6.4, 9.4, 1.7, 0.5, 8.4, 0.3, 4.3, 1.7,15.2, 13.5, 6.4, 3.8, 8.2, 11.3, 11.9, 7.1, 9, 9.9, 7.8, 5.5, 9.9, 2.6,15.5, 15.3, 0.2, 3.2, 10.1, 15, 10.3, 0, 8.8, 3.6, 15, 6.1, 3.4, 10.2, 10.1,13.7)), 
  class = "data.frame", row.names = c(NA, -80L))

head(dat)

```


The effect size is denoted with `yi`, the standard errors are denoted with `sei`, and the study-level moderator values is denoted with `xi`.

## Constructing the `brms` model

Using the `brm` function in the `brms` [@brms] package we can construct the meta-regression GAM model by utilizing the `se()` function to incorporate the sampling errors in observed effects.

```{r,warning = FALSE}

mdl <- brm(yi | se(sei, sigma = TRUE) ~ s(xi),
          data = dat, 
          family = gaussian(),
          seed = 17,
          iter = 1000, 
          warmup = 150, 
          chains = 2)

```


We can plot out the model by displaying variability in the estimate of the conditional expectation with posterior draws.


```{r}

dat %>%
  data_grid(xi = seq_range(xi, n = 51), sei = sei) %>%
  add_epred_draws(mdl, ndraws = 200) %>%
  ggplot(aes(x = xi, y = yi)) +
  geom_line(aes(y = .epred, group = .draw), alpha = .1) +
  geom_point(data = dat,aes(size = 1/sei^2), alpha = .5) +
  scale_fill_brewer(palette = "Greys") +
  scale_color_brewer(palette = "Set2") +
  theme_ggdist(base_size = 14) + 
  theme(legend.position = "none",
        aspect.ratio = .8) +
  ylab("Effect Size") +
  xlab("Moderator Value") + 
  ggtitle("GAM with Prediction Intervals")



```




Alternatively we can plot the prediction intervals showing us the variability in the true effect sizes rather than the variability in the mean of true effect sizes,



```{r}

dat %>%
  data_grid(xi = seq_range(xi, n = 51), sei = sei) %>%
  add_predicted_draws(mdl) %>%
  ggplot(aes(x = xi, y = yi)) +
  stat_lineribbon(aes(y = .prediction)) +
  geom_point(data = dat,aes(size = 1/sei^2), alpha = .5) +
  scale_fill_brewer(palette = "Greys") +
  scale_color_brewer(palette = "Set2") +
  theme_ggdist(base_size = 14) + 
  theme(legend.position = "none",
        aspect.ratio = .8) +
  ylab("Effect Size") +
  xlab("Moderator Value") + 
  ggtitle("GAM with Prediction Intervals")



```


## Predictive Check

The predictive check of the model captures the data quite well

```{r}

pp_check(mdl,nsamples = 100)

```

## Session Info

```{r}
sessionInfo()

```


## Citing R packages

The following packages were used in this post:

-   `brms` [@brms]
-   `mgcv` [@splines]
-   `tidyverse` [@tidyverse]
-   `ggdist` [@ggdist]
-   `modelr` [@modelr]
-   `tidybayes` [@tidybayes]


**Thanks to Stephen J. Wild for his advice on this post.**


<iframe src="https://embeds.beehiiv.com/f3ffd81a-4723-4419-bb1d-afc8af3bac36" data-test-id="beehiiv-embed" width="100%" height="320" frameborder="0" scrolling="no" style="border-radius: 4px; border: 2px solid #33333322; margin: 0; background-color: transparent;">

</iframe>
